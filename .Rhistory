apply(covLobo[,3:6],1,FUN = mean
)
fm.nmix1 <- pcount(~1 ~1, data=umf, control=list(trace=TRUE, REPORT=2,K=100))
fm.nmix1 <- pcount(~1 ~1, data=umf, control=list(trace=TRUE, REPORT=2), K=100)
# Detection covariates follow first tilde, then come abundance covariates
fm.nmix1 <- pcount(~1 ~1, data=umf, control=list(trace=TRUE, REPORT=2), K=100)
fm.nmix2 <- pcount(~1 ~covLobo, data=umf, control=list(trace=TRUE, REPORT=2),K=100)
fm.nmix3 <- pcount(~1 ~covPoly, data=umf, control=list(trace=TRUE, REPORT=2),K=100)
fm.nmix4 <- pcount(~obsLobo ~1, data=umf, control=list(trace=TRUE, REPORT=2),K=100)
fm.nmix5 <- pcount(~obsPoly ~1, data=umf, control=list(trace=TRUE, REPORT=2),K=100)
fm.nmix2nb <- pcount(~1 ~covLobo, data=umf, mixture="NB", control=list(trace=TRUE, REPORT=2),K=100)
fm.nmix2zip <- pcount(~1 ~covLobo, data=umf, mixture="ZIP", control=list(trace=TRUE, REPORT=2),K=100)
covLobo
covPoly
models <- fitList(
'p(.)lambda(.)' = fm.nmix1,
'p(.)lambda(covLobo)' = fm.nmix2,
'p(.)lambda(covPoly)' = fm.nmix3,
'p(obsLobo)lambda(.)' = fm.nmix4,
'p(obsPoly)lambda(.)' = fm.nmix5,
'p(.)lambda(covLobo)nb' = fm.nmix2nb,
'p(.)lambda(covLobo)zip' = fm.nmix2zip)
ms <- modSel(models)
ms
apply(covLobo[,3:6],1,FUN = mean)
apply(covLobo[,3:6],1,FUN = sum)
umf <- unmarkedFramePCount(y=erizoexpanded_sp1[,3:6], # chane acording to month number
siteCovs= data.frame(
covLobo= apply(covLobo[,3:6],1,FUN = sum),
covPoly=apply(covPoly[,3:6],1,FUN = sum)),
obsCovs = list(obsLobo = covLobo[3:6],
obsPoly = covPoly[3:6]))
summary(umf)
# Detection covariates follow first tilde, then come abundance covariates
fm.nmix1 <- pcount(~1 ~1, data=umf, control=list(trace=TRUE, REPORT=2), K=300)
fm.nmix2 <- pcount(~1 ~covLobo, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix3 <- pcount(~1 ~covPoly, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix4 <- pcount(~obsLobo ~1, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix5 <- pcount(~obsPoly ~1, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix2nb <- pcount(~1 ~covLobo, data=umf, mixture="NB", control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix2zip <- pcount(~1 ~covLobo, data=umf, mixture="ZIP", control=list(trace=TRUE, REPORT=2),K=300)
models <- fitList(
'p(.)lambda(.)' = fm.nmix1,
'p(.)lambda(covLobo)' = fm.nmix2,
'p(.)lambda(covPoly)' = fm.nmix3,
'p(obsLobo)lambda(.)' = fm.nmix4,
'p(obsPoly)lambda(.)' = fm.nmix5,
'p(.)lambda(covLobo)nb' = fm.nmix2nb,
'p(.)lambda(covLobo)zip' = fm.nmix2zip)
ms <- modSel(models)
ms
erizoexpanded_sp1[,3:6]
coef(fm.nmix1)
beta1 <- coef(fm.nmix1)
plot(function(x) exp(beta1[1] + beta1[2]*x), 0, 15,
xlab="otra_sp", ylab="Expected Abundance")
beta1
plogis(coef(fm.nmix1, type="det")) # Should be close to p
backTransform(fm.nmix1, type="det")
## GoF analysis
## define a fit statistic
freeTuke <- function(fm) {
observed <- getY(fm@data)
expected <- fitted(fm)
sum((sqrt(observed) - sqrt(expected))^2)
}
pb.bestfit <- parboot(fm.nmix1, freeTuke, nsim=300, report=1)
plot(pb.bestfit)
pb.bestfit
pb.bestfit
(fm1re <- ranef(fm.nmix1))
Nnaive<-sum(apply(erizoexpanded_sp1[,3:6],2,sum))
Nnaive
apply(erizoexpanded_sp1[,3:6],2,sum)
umf <- unmarkedFramePCount(y=erizoexpanded_sp2[,3:6], # chane acording to month number
siteCovs= data.frame(
covLobo= apply(covLobo[,3:6],1,FUN = sum),
covPoly=apply(covPoly[,3:6],1,FUN = sum)),
obsCovs = list(obsLobo = covLobo[3:6],
obsPoly = covPoly[3:6]))
summary(umf)
# Detection covariates follow first tilde, then come abundance covariates
fm.nmix1 <- pcount(~1 ~1, data=umf, control=list(trace=TRUE, REPORT=2), K=300)
fm.nmix2 <- pcount(~1 ~covLobo, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix3 <- pcount(~1 ~covPoly, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix4 <- pcount(~obsLobo ~1, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix5 <- pcount(~obsPoly ~1, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix2nb <- pcount(~1 ~covLobo, data=umf, mixture="NB", control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix2zip <- pcount(~1 ~covLobo, data=umf, mixture="ZIP", control=list(trace=TRUE, REPORT=2),K=300)
models <- fitList(
'p(.)lambda(.)' = fm.nmix1,
'p(.)lambda(covLobo)' = fm.nmix2,
'p(.)lambda(covPoly)' = fm.nmix3,
'p(obsLobo)lambda(.)' = fm.nmix4,
'p(obsPoly)lambda(.)' = fm.nmix5,
'p(.)lambda(covLobo)nb' = fm.nmix2nb,
'p(.)lambda(covLobo)zip' = fm.nmix2zip)
ms <- modSel(models)
ms
beta1 <- coef(fm.nmix3)
plot(function(x) exp(beta1[1] + beta1[2]*x), 0, 15,
xlab="otra_sp", ylab="Expected Abundance")
covPoly
newdat <- data.frame(covPoly=c(0:100))
predict(fm.nmix2, type="state", newdata=newdat, appendData = T)
newdat <- data.frame(covPoly=c(0:100))
predict(fm.nmix3, type="state", newdata=newdat, appendData = T)
warnings()
fm.nmix3
fm.nmix3 <- pcount(~1 ~covPoly, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix3
plot(predict(fm.nmix3, type="state", newdata=newdat, appendData = T))
pred<-predict(fm.nmix3, type="state", newdata=newdat, appendData = T)
pred
plot(pred$covPoly,pred$Predicted)
plogis(coef(fm.nmix3, type="det")) # Should be close to p
backTransform(fm.nmix3, type="det")
coef(fm.nmix3, type="det")
backTransform(fm.nmix3, type="state")
fm.nmix3
backTransform(fm.nmix3, type="det")
backTransform(fm.nmix3, type="state")
plogis(coef(fm.nmix3, type="state"))
(fm1re <- ranef(fm.nmix1))
sum(bup(fm1re))         # Estimated population size
erizoexpanded_sp2[,3:6]
ms
covPoly[3:6]
obsCovs
obsCovs = list(obsLobo = covLobo[3:6],
obsPoly = covPoly[3:6])
obsCovs
plogis(coef(fm1, type="det")) # Should be close to p
fm1
summary(umf)
data.frame(x=x)
obsCovs=list(visit=visitMat)
list(visit=visitMat)
visitMat <- matrix(as.character(1:4), 15, 4, byrow=TRUE))
as.character(1:4)
visitMat <- matrix(as.character(1:4), 15, 4, byrow=TRUE)
visitMat
library(unmarked)
umf <- unmarkedFramePCount(y=erizoexpanded_sp2[,3:6], # chane acording to month number
siteCovs= data.frame(
covLobo= apply(covLobo[,3:6],1,FUN = sum),
covPoly=apply(covPoly[,3:6],1,FUN = sum)),
obsCovs = list(obsLobo = covLobo[3:6],
obsPoly = covPoly[3:6],
visit=visitMat))
summary(umf)
ms
fm.nmix6 <- pcount(~visit ~covPoly, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix6
fm.nmix2
models <- fitList(
'p(.)lambda(.)' = fm.nmix1,
'p(.)lambda(covLobo)' = fm.nmix2,
'p(.)lambda(covPoly)' = fm.nmix3,
'p(obsLobo)lambda(.)' = fm.nmix4,
'p(obsPoly)lambda(.)' = fm.nmix5,
'p(.)lambda(covLobo)nb' = fm.nmix2nb,
'p(.)lambda(covLobo)zip' = fm.nmix2zip,
'p(visit)lambda(covPoly)' = fm.nmix6)
fm.nmix6
models <- fitList(
'p(.)lambda(.)' = fm.nmix1,
'p(.)lambda(covLobo)' = fm.nmix2,
'p(.)lambda(covPoly)' = fm.nmix3,
'p(obsLobo)lambda(.)' = fm.nmix4,
'p(obsPoly)lambda(.)' = fm.nmix5,
'p(.)lambda(covLobo)nb' = fm.nmix2nb,
'p(.)lambda(covLobo)zip' = fm.nmix2zip,
'p(visit)lambda(covPoly)' = fm.nmix6)
ms <- modSel(models)
fm.nmix6 <- pcount(~visit ~1, data=umf, control=list(trace=TRUE, REPORT=2),K=300)
fm.nmix6
models <- fitList(
'p(.)lambda(.)' = fm.nmix1,
'p(.)lambda(covLobo)' = fm.nmix2,
'p(.)lambda(covPoly)' = fm.nmix3,
'p(obsLobo)lambda(.)' = fm.nmix4,
'p(obsPoly)lambda(.)' = fm.nmix5,
'p(.)lambda(covLobo)nb' = fm.nmix2nb,
'p(.)lambda(covLobo)zip' = fm.nmix2zip,
'p(visit)lambda(.)' = fm.nmix6)
ms
fm.nmix5
fm.nmix6
visitMat
fm.nmix2
ms
1500*1.95
# Function returning three fit-statistics.
fitstats <- function(fm) {
observed <- getY(fm@data)
expected <- fitted(fm)
resids <- residuals(fm)
sse <- sum(resids^2)
chisq <- sum((observed - expected)^2 / expected)
freeTuke <- sum((sqrt(observed) - sqrt(expected))^2)
out <- c(SSE=sse, Chisq=chisq, freemanTukey=freeTuke)
return(out)
}
(pb <- parboot(fm.nmix3, fitstats, nsim=25, report=1))
plot(pb, main="")
plot(pb, main="")
pb.bestfit
parboot
parboot()
2000*1.95
29250000 - 15309375
install.packages("siar")
library(siar)
mydata <- read.delim("data/nicho_QUI2.txt")
View(mydata)
ngroups <- length(unique(mydata$group))
View(mydata)
spx <- split(x,group)
View(mydata)
spx <- split(mydata$x,group)
spx <- split(mydata$x,mydata$group)
spy <- split(mydata$y,mydata$group)
SEA <- numeric(ngroups)
SEAc <- numeric(ngroups)
TA <- numeric(ngroups)
TA
SEAc
plot(x,y,col="black",pch=c(1,2)[as.numeric(group)], xlab="", ylab="", ylim=c(11, 15), xlim=c(-17, -15), cex.axis=0.8)
plot(mydata$x,mydata$y,col="black",pch=c(1,2)[as.numeric(mydata$group)], xlab="", ylab="", ylim=c(11, 15), xlim=c(-17, -15), cex.axis=0.8)
mtext(expression(""*delta*""^13*"C(\u2030)"), side=1,line=3,cex=1.2)
mtext(expression(""*delta*""^15*"N(\u2030)"), side=2,line=2.2,cex=1.2)
for (j in unique(mydata$group)){
SE <- standard.ellipse(spx[[j]],spy[[j]],steps=1)
SEA[j] <- SE$SEA
SEAc[j] <- SE$SEAc
lines(SE$xSEAc,SE$ySEAc,col="black",lty=1,lwd=1)
CH <- convexhull(spx[[j]],spy[[j]])
TA[j] <- CH$TA
}
print(cbind(SEA,SEAc))
print(cbind(SEA,SEAc,TA))
SEA.B <- siber.ellipses(mydata$x,mydata$y,mydata$group,R=reps)
reps <- 10^4 # the number of posterior draws to make
# Generate the Bayesian estimates for the SEA for each group using the
# utility function siber.ellipses
SEA.B <- siber.ellipses(mydata$x,mydata$y,mydata$group,R=reps)
mydata$x
reps
SEA.B <- siber.ellipses(as.matrix(mydata$x,mydata$y,mydata$group,R=reps))
mydata$group
as.matrix(mydata$x,mydata$y,mydata$group,R=reps)
mydata$group
reps
SEA.B <- siber.ellipses(mydata$x,mydata$y,mydata$group,R=reps)
mydata$x
mydata$y
mydata$group
siber.ellipses(mydata$x,mydata$y,mydata$group,R=reps)
print(cbind(SEA,SEAc))
print(cbind(SEA,SEAc,TA))
siber.ellipses(mydata$x, mydata$y, mydata$group, R=100)
siber.ellipses
SEA.B <- siber.ellipses(mydata$x, mydata$y, 2, R=100)
SEA.B <- siber.ellipses(mydata$x, mydata$y, 2, R=100)
SEA.B <- siber.ellipses(x=mydata$x, y=mydata$y, mydata$group, R=100)
SEA.B <- siber.ellipses(x=mydata$x, y=mydata$y, 2, R=100)
SEA.B <- siber.ellipses(x=as.vector(mydata$x), y=as.vector(mydata$y), 2, R=100)
as.vector(mydata$y)
SEA.B <- siber.ellipses(x=as.vector(mydata$x), y=as.vector(mydata$y), group=2, R=100)
matrix(data = 0, nrow = R, ncol = ngroups)
matrix(data = 0, nrow = 100, ncol = ngroups)
ngroups
SEA.B <- siber.ellipses(x=as.vector(mydata$x), y=as.vector(mydata$y), group=ngroups, R=100)
mydata$group
siber.ellipses
ngroups <- length(unique(group))
ngroups <- length(unique(mydata$group))
length(unique(group))
group<-ngroups
ngroups <- length(unique(group))
spx <- split(x, group)
group<-ngroup
group<-ngroup
ngroup
x<-as.vector(mydata$x)
y<-as.vector(mydata$y)
group<-ngroups
ngroups <- length(unique(group))
spx <- split(x, group)
spy <- split(y, group)
SEA.B <- matrix(data = 0, nrow = R, ncol = ngroups)
R<-100
SEA.B <- matrix(data = 0, nrow = R, ncol = ngroups)
for (j in 1:ngroups) {
model <- bayesMVN(spx[[j]], spy[[j]], R = R)
Nobs <- nrow(model$b)
for (i in 1:Nobs) {
estS <- model$S[i, ]
dim(estS) <- c(2, 2)
SEA.B[i, j] <- popSEA(estS)$SEA
}
}
ngroups
ngroups
ngroups <- length(unique(mydata$group))
ngroups
group<-ngroups
R<-100
length(unique(group))
length(unique(group))
ngroups <- 2
spx <- split(x, group)
spy <- split(y, group)
SEA.B <- matrix(data = 0, nrow = R, ncol = ngroups)
for (j in 1:ngroups) {
model <- bayesMVN(spx[[j]], spy[[j]], R = R)
Nobs <- nrow(model$b)
for (i in 1:Nobs) {
estS <- model$S[i, ]
dim(estS) <- c(2, 2)
SEA.B[i, j] <- popSEA(estS)$SEA
}
}
split(x, group)
split(y, group)
matrix(data = 0, nrow = R, ncol = ngroups)
ngroups
j<-1
bayesMVN(spx[[j]], spy[[j]], R = R)
bayesMVN(spx[[j]], spy[[j]], R = R)
bayesMVN(spx[[j]], spy[[j]], R = R)
bayesMVN
spx[[j]]
spy[[j]]
model <- bayesMVN(spx[[j]], spy[[j]], R = R)
y
Y <- cbind(x, y)
X <- matrix(1, length(x), 1)
X
Bbar <- c(0, 0)
A <- 10^-3
nu <- 2
V <- 2 * diag(2)
b <- matrix(double(R * 2), ncol = 2)
S <- matrix(double(R * 4), ncol = 4)
b
i<-1
out <- rmultireg(Y, X, Bbar, A, nu, V)
rmultireg
bayesm_rmultireg
bayesm_rmultireg
rmultireg
out <- rmultireg(Y, X, Bbar, A, nu, V)
rmultireg<-function (Y, X, Bbar, A, nu, V){
.Call("rmultireg", PACKAGE = "bayesm", Y, X, Bbar,
A, nu, V)
}
out <- rmultireg(Y, X, Bbar, A, nu, V)
rmultireg<-function (Y, X, Bbar, A, nu, V){
.Call("bayesm_rmultireg", PACKAGE = "bayesm", Y, X, Bbar,
A, nu, V)
}
out <- rmultireg(Y, X, Bbar, A, nu, V)
rmultireg
rmultireg(Y, X, Bbar, A, nu, V)
out <- rmultireg(Y, X, Bbar, A, nu, V)
V
Y
X
matrix(1, length(x), 1)
length(x)
Bbar
A
V
mydata <- read.delim("data/nicho_QUI2.txt")
attach(mydata)
mydata
ngroups <- length(unique(group))
spx <- split(x,roup)
spx <- split(x,group)
spy <- split(y,group)
spy
SEA <- numeric(ngroups)
SEAc <- numeric(ngroups)
TA <- numeric(ngroups)
plot(x,y,col="black",pch=c(1,2)[as.numeric(group)], xlab="", ylab="", ylim=c(11, 15), xlim=c(-17, -15), cex.axis=0.8)
mtext(expression(""*delta*""^13*"C(\u2030)"), side=1,line=3,cex=1.2)
mtext(expression(""*delta*""^15*"N(\u2030)"), side=2,line=2.2,cex=1.2)
for (j in unique(mydata$group)){
SE <- standard.ellipse(spx[[j]],spy[[j]],steps=1)
SEA[j] <- SE$SEA
SEAc[j] <- SE$SEAc
lines(SE$xSEAc,SE$ySEAc,col="black",lty=1,lwd=1)
CH <- convexhull(spx[[j]],spy[[j]])
TA[j] <- CH$TA
}
for (j in unique(mydata$group)){
SE <- standard.ellipse(spx[[j]],spy[[j]],steps=1)
SEA[j] <- SE$SEA
SEAc[j] <- SE$SEAc
lines(SE$xSEAc,SE$ySEAc,col="black",lty=1,lwd=1)
CH <- convexhull(spx[[j]],spy[[j]])
TA[j] <- CH$TA
}
for (j in unique(group)){
SE <- standard.ellipse(spx[[j]],spy[[j]],steps=1)
SEA[j] <- SE$SEA
SEAc[j] <- SE$SEAc
lines(SE$xSEAc,SE$ySEAc,col="black",lty=1,lwd=1)
CH <- convexhull(spx[[j]],spy[[j]])
TA[j] <- CH$TA
}
group
groups
for (j in unique(ngroups)){
SE <- standard.ellipse(spx[[j]],spy[[j]],steps=1)
SEA[j] <- SE$SEA
SEAc[j] <- SE$SEAc
lines(SE$xSEAc,SE$ySEAc,col="black",lty=1,lwd=1)
CH <- convexhull(spx[[j]],spy[[j]])
TA[j] <- CH$TA
}
ngroups
ngroups
length(unique(group))
group
mydata
length(unique(group))
ngroups <- 2
for (j in unique(ngroups)){
SE <- standard.ellipse(spx[[j]],spy[[j]],steps=1)
SEA[j] <- SE$SEA
SEAc[j] <- SE$SEAc
lines(SE$xSEAc,SE$ySEAc,col="black",lty=1,lwd=1)
CH <- convexhull(spx[[j]],spy[[j]])
TA[j] <- CH$TA
}
mydata <- read.delim("data/nicho_QUI2.txt")
attach(mydata)
rm()
detach(mydata)
attach(mydata)
mydata
ngroups <- length(unique(group))
ngroups
group
rm(group)
ngroups <- length(unique(group))
ngroups
ngroups <- length(unique(group))
spx <- split(x,group)
spy <- split(y,group)
# create some empty vectors for recording our metrics
SEA <- numeric(ngroups)
SEAc <- numeric(ngroups)
TA <- numeric(ngroups)
dev.new()
plot(x,y,col="black",pch=c(1,2)[as.numeric(group)], xlab="", ylab="", ylim=c(11, 15), xlim=c(-17, -15), cex.axis=0.8)
mtext(expression(""*delta*""^13*"C(\u2030)"), side=1,line=3,cex=1.2)
mtext(expression(""*delta*""^15*"N(\u2030)"), side=2,line=2.2,cex=1.2)
for (j in unique(group)){
SE <- standard.ellipse(spx[[j]],spy[[j]],steps=1)
SEA[j] <- SE$SEA
SEAc[j] <- SE$SEAc
lines(SE$xSEAc,SE$ySEAc,col="black",lty=1,lwd=1)
CH <- convexhull(spx[[j]],spy[[j]])
TA[j] <- CH$TA
}
print(cbind(SEA,SEAc))
print(cbind(SEA,SEAc,TA))
reps <- 10^4 # the number of posterior draws to make
SEA.B <- siber.ellipses(x,y,group,R=reps)
mydata <- read.delim("data/nicho_QUI2.txt")
attach(mydata)
#detach(mydata)
ngroups <- length(unique(group))
# split the isotope data based on group
spx <- split(x,group)
spy <- split(y,group)
# create some empty vectors for recording our metrics
SEA <- numeric(ngroups)
SEAc <- numeric(ngroups)
TA <- numeric(ngroups)
dev.new()
plot(x,y,col="black",pch=c(1,2)[as.numeric(group)], xlab="", ylab="", ylim=c(11, 15), xlim=c(-17, -15), cex.axis=0.8)
mtext(expression(""*delta*""^13*"C(\u2030)"), side=1,line=3,cex=1.2)
mtext(expression(""*delta*""^15*"N(\u2030)"), side=2,line=2.2,cex=1.2)
for (j in unique(group)){
SE <- standard.ellipse(spx[[j]],spy[[j]],steps=1)
SEA[j] <- SE$SEA
SEAc[j] <- SE$SEAc
lines(SE$xSEAc,SE$ySEAc,col="black",lty=1,lwd=1)
CH <- convexhull(spx[[j]],spy[[j]])
TA[j] <- CH$TA
}
reps <- 10^4 # the number of posterior draws to make
SEA.B <- siber.ellipses(x,y,group,R=reps)
overlap.G1.G3 <- overlap(spx[[1]],spy[[1]],spx[[2]],spy[[2]],steps=1)
overlap.G1.G3
siardensityplot(SEA.B, xlab=" ",ylab=" ")
Pg1.lt.g2 <- sum( SEA.B[,1] < SEA.B[,2] ) / nrow(SEA.B)
Pg1.lt.g2
siarmenu()
siarmenu()
siarmenu()
siarmenu()
geese2demo
siarmenu()
siarmenu()
SEA.B <- siber.ellipses(x,y,group,R=reps)
12*3

{
    "contents" : "\n\n# -----------------------------------------------------------------------\n# ------------------------ Poisson regression  -------------------------\n# -----------------------------------------------------------------------\n\n\n# ------------------------- Simulate data ------------------------------\n\n# PART 1: Set-up the data (simulate it here)\n#\n# Create a covariate called vegHt\nnSites <- 100\nset.seed(443)                # so that we all get the same values of vegHt\nvegHt <- runif(nSites, 1, 3) # uniform from 1 to 3\n\n\n# Suppose that expected population size increases with vegHt\n# The relationship is described by an intercept of -3 and\n#    a slope parameter of 2 on the log scale\n\nlambda <- exp(-3 + 2*vegHt)\n\n\n# Now we go to 100 sites and observe the # of individuals (perfectly)\n# \nN <- rpois(nSites, lambda)\n\n\n## PART 2: Fit some models\n##\n##\n# We can fit a model that relates abundance to vegHt using the glm() function\n#  with \"family=Poisson\":\n\nfm.glm1 <- glm(N ~ vegHt, family=poisson)\n\n##\n## PART 3: Do some analysis of the results\n##\nplot(vegHt, N, xlab=\"Vegetation height\", ylab=\"Abundance (N)\")\nglm1.est <- coef(fm.glm1)\nplot(function(x) exp(-3 + 2*x), 1, 3, add=TRUE, lwd=2)\nplot(function(x) exp(glm1.est[1] + glm1.est[2]*x), 1, 3, add=TRUE,\n     lwd=2, col=\"blue\")\nlegend(1, 15.9, c(\"Truth\", \"Estimate\"), col=c(\"black\", \"blue\"), lty=1,\n       lwd=2)\n\n\n\n# -----------------------------------------------------------------------\n# ------ Imperfect observation of abundance using a binomial sampling model\n## ----- suppose y is a BINOMIAL sample based on population size N and parameter\n## ----- p = \"detection probability\". i.e.,:\n## -----   y ~ binomial(N, p)\n## ----- the canonical \"point counting\" model\n## ----- In practice, we think p < 1, say p = 0.6. This is INDIVIDUAL-LEVEL\n## ------ detection -- i.e., each individual is detected with probability p\n##\n## ----- In this case, N is a LATENT VARIABLE (i.e., unobserved).\n# -----------------------------------------------------------------------\n\n\n\nnVisits <- 4\np <- 0.6\ny <- matrix(NA, nSites, nVisits)\nfor(i in 1:nSites) {\n    y[i,] <- rbinom(nVisits, N[i], p)\n}\n\n# Format for unmarked and summarize\nlibrary(unmarked)\numf <- unmarkedFramePCount(y=y, siteCovs=as.data.frame(vegHt))\nsummary(umf)\n\n# Fit a model and extract estimates\n# Detection covariates follow first tilde, then come abundance covariates\n\nfm.nmix1 <- pcount(~1 ~vegHt, data=umf)\n\n# Note the following warning message:\n#> fm.nmix1 <- pcount(~1 ~vegHt, data=umf)\n#Warning message:\n#In pcount(~1 ~ vegHt, data = umf) : K was not specified and was set to 116.\n# K is upper limit of summation for calculating the likelihood\n\n# Consider other abundance models: NB = negative binomial, ZIP = zero-inflated Poisson\n## currently no others available. \n##\nfm.nmix2<-  pcount(~1 ~vegHt, data=umf,mixture=\"NB\")\nfm.nmix3<-  pcount(~1 ~vegHt, data=umf,mixture=\"ZIP\")\nbeta1 <- coef(fm.nmix1) \n\n\n#\n# Note, estimates of detection coefficients are on the logit-scale\n# When there are no covariates, we can back-transform using:\nexp(beta1[3]) / (1+exp(beta1[3]))   # or\nplogis(beta1[3])                    # or\nbackTransform(fm.nmix1, type=\"det\") # estimate with SE\n\n# When covariates are present we can do something like\n#\nplot(function(x) exp(beta1[1] + beta1[2]*x), 1, 3,\n     xlab=\"vegetation height\", ylab=\"Expected Abundance\")\n\n\n# Or suppose you want predictions for new values of vegHt, say 1.2 and 3.1\nnewdat <- data.frame(vegHt=c(1.2, 3.1))\npredict(fm.nmix1, type=\"state\", newdata=newdat)\n\n\n#\n# -----------------------------------------------------------------------\n# ----------- Now let's start from scratch with real data --------------\n# -----------------------------------------------------------------------\n#\n\n\n\n# PART 1: Set-up the data for analysis\n#\n#\n# -------------------------- Format data ---------------------------------\n# This a subset of point-count data from Chandler et al. (Auk 2009)\n# alfl is Alder Flycatcher (Empidonax alnorum)\n\n# Import data and check structure\n#alfl.data <- read.csv(\"alfl05.csv\", row.names=1)\nalfl.data <- read.csv(\"http://sites.google.com/site/unmarkedinfo/home/webinars/2012-january/data/alfl05.csv?attredirects=0&d=1\", row.names=1)\n\nstr(alfl.data)\n\n\n# Pull out count matrix \n# No need to covert to binary as we did for occupancy model\n\nalfl.y <- alfl.data[,c(\"alfl1\", \"alfl2\", \"alfl3\")]\n\n# Standardize site-covariates\nwoody.mean <- mean(alfl.data$woody)\nwoody.sd <- sd(alfl.data$woody)\nwoody.z <- (alfl.data$woody-woody.mean)/woody.sd\n\nstruct.mean <- mean(alfl.data$struct)\nstruct.sd <- sd(alfl.data$struct)\nstruct.z <- (alfl.data$struct-struct.mean)/struct.sd\n\n\n# Create unmarkedFrame\nlibrary(unmarked)\nalfl.umf <- unmarkedFramePCount(y=alfl.y,\n    siteCovs=data.frame(woody=woody.z, struct=struct.z),\n    obsCovs=list(time=alfl.data[,c(\"time.1\", \"time.2\", \"time.3\")],\n                 date=alfl.data[,c(\"date.1\", \"date.2\", \"date.3\")]))\nsummary(alfl.umf)\n\n\n# Here's an easy way to standardize covariates after making the UMF\nobsCovs(alfl.umf) <- scale(obsCovs(alfl.umf))\nsummary(alfl.umf)\n\n\n#\n#\n# PART 2: Fit some models\n#\n# -------------------------- Model fitting  -----------------------------\n\n(fm1 <-  pcount(~1 ~1, alfl.umf))\nbackTransform(fm1, type=\"state\")\nbackTransform(fm1, type=\"det\")\n\n(fm2 <- pcount(~date+time ~1, alfl.umf))\n(fm3 <- pcount(~date+time ~woody, alfl.umf))\n(fm4 <- pcount(~date+time ~woody+struct, alfl.umf))\n(fm5 <- pcount(~date+time ~1, alfl.umf,mixture=\"NB\"))\n(fm6 <- pcount(~date+time ~1, alfl.umf,mixture=\"ZIP\"))\n(fm7 <- pcount(~date+time ~woody,alfl.umf,mixture=\"ZIP\"))\n(fm8 <- pcount(~date+time ~struct,alfl.umf,mixture=\"ZIP\"))\n(fm9 <- pcount(~date+time ~woody+struct, alfl.umf,mixture=\"ZIP\"))\n(fm10<- pcount(~date+time ~woody+struct, alfl.umf,mixture=\"NB\"))\n\n# -------------------------- Model selection -----------------------------\n\n# Put the fitted models in a \"fitList\"\nfms <- fitList(\"lam(.)p(.)\"                    = fm1,\n               \"lam(.)p(date+time)\"            = fm2,\n               \"lam(woody)p(date+time)\"        = fm3,\n               \"lam(woody+struct)p(date+time)\" = fm4,\n               \"lam(.)p(date+time)NB\"          = fm5,\n               \"lam(.)p(date+time)ZIP\"         = fm6,\n               \"lam(woody)p(date+time)ZIP\"     = fm7,\n               \"lam(struct)p(date+time)ZIP\"    = fm8,\n               \"lam(woody+struct)p(date+time)ZIP\"=fm9,\n               \"lam(woody+struct)p(date+time)NB\" =fm10)\n\n# Rank them by AIC\n(ms <- modSel(fms))\n\n# Table with everything you could possibly need\ncoef(ms)\ntoExport <- as(ms, \"data.frame\")\n\n\n#\n#\n# PART 3: Do some analysis of the results\n#\n#\n# ---------------------------- Prediction --------------------------------\n\n\n# Expected detection probability as function of time of day\n# We standardized \"time\", so we predict over range of values on that scale\n# We must fix \"date\" at some arbitrary value (let's use the mean)\nnewData1 <- data.frame(time=seq(-2.08, 1.86, by=0.1), date=0)\nE.p <- predict(fm4, type=\"det\", newdata=newData1, appendData=TRUE)\nhead(E.p)\n\npar(mfrow=c(2,1))\n# Plot it\nplot(Predicted ~ time, E.p, type=\"l\", ylim=c(0,1),\n     xlab=\"time of day (standardized)\",\n     ylab=\"Expected detection probability\")\nlines(lower ~ time, E.p, type=\"l\", col=gray(0.5))\nlines(upper ~ time, E.p, type=\"l\", col=gray(0.5))\n\n\n\n# Expected abundance over range of \"woody\"\nnewData2 <- data.frame(woody=seq(-1.6, 2.38,,50),struct=seq(-1.8,3.2,,50))\nE.N <- predict(fm4, type=\"state\", newdata=newData2, appendData=TRUE)\nhead(E.N)\n\n# Plot predictions with 95% CI\nplot(Predicted ~ woody, E.N, type=\"l\", ylim=c(-.1,max(E.N$Predicted)),\n     xlab=\"woody vegetation (standardized)\",\n     ylab=\"Expected abundance, E[N]\")\nlines(lower ~ woody, E.N, type=\"l\", col=gray(0.5))\nlines(upper ~ woody, E.N, type=\"l\", col=gray(0.5))\n\npar(mfrow=c(1,1))\n# Plot it again, but this time convert the x-axis back to original scale\nplot(Predicted ~ woody, E.N, type=\"l\", ylim=c(-.1,max(E.N$Predicted)),\n     xlab=\"Percent cover - woody vegetation\",\n     ylab=\"Expected abundance, E[N]\",\n     xaxt=\"n\")\nxticks <- -1:2\nxlabs <- xticks*woody.sd + woody.mean\naxis(1, at=xticks, labels=round(xlabs, 1))\nlines(lower ~ woody, E.N, type=\"l\", col=gray(0.5))\nlines(upper ~ woody, E.N, type=\"l\", col=gray(0.5))\n\n\n## Goodness-of-Fit\n###\n###\n### Here's an example of a bootstrap GoF analysis.\n### Best model is in \"fm4\" object\n###\n\n# Function returning three fit-statistics.\nfitstats <- function(fm) {\n    observed <- getY(fm@data)\n    expected <- fitted(fm)\n    resids <- residuals(fm)\n    sse <- sum(resids^2)\n    chisq <- sum((observed - expected)^2 / expected)\n    freeTuke <- sum((sqrt(observed) - sqrt(expected))^2)\n    out <- c(SSE=sse, Chisq=chisq, freemanTukey=freeTuke)\n    return(out)\n    }\n\n(pb <- parboot(fm4, fitstats, nsim=100, report=1))\n### To look at bootstrap distributions do this\n###plot(pb, main=\"\")\nprint(pb)\n\n## Now lets bootstrap a summary statistic \n## This is not too meaningful right now but we will do a similar thing later in \n## a more relevant context\n\n# Total population size (derived parameter)\nNhat <- function(fm) {\n    N <- sum(predict(fm, type=\"state\")$Predicted, na.rm=TRUE)\n    }\n    \n(pb.N <- parboot(fm4, Nhat, nsim=25, report=5))\nplot(pb.N)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Here's an example of model-averaging predictions\n# See pg 150, section 4.2.1, of Burnham and Anderson (2002)\n# This might be worthwhile since fm3 and fm4 had similar support\n\nnewData3 <- data.frame(woody=seq(-1.6, 2.38,,50), struct=seq(-1.8,3.2,,50))\n\n## averages over _all_ models in the fit list \"fms\":\nE.N.bar <- predict(fms, type=\"state\", newdata=newData3,\n                     appendData=TRUE)\nhead(E.N.bar)\n\n# Plot it\nplot(Predicted ~ woody, E.N.bar, type=\"l\", ylim=c(-0.1, max(E.N$Predicted)),\n     xlab=\"Percent cover - woody vegetation\",\n     ylab=\"Expected abundance, E[N]\",\n     xaxt=\"n\")\nxticks <- -1:2\nxlabs <- xticks*woody.sd + woody.mean\naxis(1, at=xticks, labels=round(xlabs, 1))\nlines(lower ~ woody, E.N.bar, type=\"l\", col=gray(0.5))\nlines(upper ~ woody, E.N.bar, type=\"l\", col=gray(0.5))\n\n",
    "created" : 1442340676358.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3558621583",
    "id" : "CC3D24B",
    "lastKnownWriteTime" : 1420139186,
    "path" : "~/CodigoR/Occupancy Course/code/moduleABUN_ALFL.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 9,
    "source_on_save" : false,
    "type" : "r_source"
}